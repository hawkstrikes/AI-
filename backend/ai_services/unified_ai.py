"""
ç»Ÿä¸€AIæœåŠ¡ - æ•´åˆå¤šä¸ªAIæ¨¡å‹å½¢æˆå¤šæ ·æ€§èŠå¤©æ•ˆæœ
"""

import os
import random
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

# å¯¼å…¥å…·ä½“çš„AIæœåŠ¡
from .deepseek import DeepSeekAI
from .minimax import MinimaxAI
from .stepchat import StepChatAI

logger = logging.getLogger(__name__)

def load_env_file(file_path):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value

class UnifiedAIService:
    """ç»Ÿä¸€AIæœåŠ¡ - æ•´åˆå¤šä¸ªAIæ¨¡å‹"""
    
    def __init__(self):
        # ä¸»åŠ¨åŠ è½½ç¯å¢ƒå˜é‡
        self._load_environment()
        
        self.ai_models = {
            'deepseek': {
                'name': 'DeepSeek',
                'description': 'æ·±åº¦æ€è€ƒå‹AIï¼Œæ“…é•¿é€»è¾‘åˆ†æå’Œå¤æ‚æ¨ç†',
                'personality': 'ä¸¥è°¨ã€ç†æ€§ã€å–„äºåˆ†æ',
                'style': 'formal',
                'temperature': 0.7
            },
            'minimax': {
                'name': 'MiniMax', 
                'description': 'å‹å¥½å¯¹è¯å‹AIï¼Œæ“…é•¿æ—¥å¸¸äº¤æµå’Œæƒ…æ„Ÿè¡¨è¾¾',
                'personality': 'å‹å¥½ã€å¹½é»˜ã€å–„äºå€¾å¬',
                'style': 'casual',
                'temperature': 0.8
            },
            'stepchat': {
                'name': 'StepChat',
                'description': 'åˆ›æ„çµæ„Ÿå‹AIï¼Œæ“…é•¿åˆ›æ–°æ€ç»´å’Œè‰ºæœ¯è¡¨è¾¾',
                'personality': 'åˆ›æ„ã€å¼€æ”¾ã€å¯Œæœ‰æƒ³è±¡åŠ›',
                'style': 'creative',
                'temperature': 0.9
            }
        }
        
        # åˆå§‹åŒ–AIæœåŠ¡å®ä¾‹
        self.ai_services = {}
        self._init_ai_services()
        
        # å¯¹è¯å†å²è®°å½•
        self.conversation_history = {}
        
        # ç”¨æˆ·åå¥½åˆ†æ
        self.user_preferences = {}
        
        # æ¨¡æ‹Ÿæ¨¡å¼æ ‡å¿—
        self.simulation_mode = False
        
    def _load_environment(self):
        """åŠ è½½ç¯å¢ƒå˜é‡"""
        try:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            current_dir = Path(__file__).parent.parent.parent.absolute()
            
            # å°è¯•åŠ è½½ä¸åŒçš„é…ç½®æ–‡ä»¶
            config_files = [
                current_dir / 'backend' / 'config.env',
                current_dir / '.env',
                current_dir / 'production.env'
            ]
            
            for config_file in config_files:
                if os.path.exists(config_file):
                    load_env_file(config_file)
                    logger.info(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {config_file}")
                    break
                    
        except Exception as e:
            logger.error(f"åŠ è½½ç¯å¢ƒå˜é‡å¤±è´¥: {e}")
        
    def _init_ai_services(self):
        """åˆå§‹åŒ–AIæœåŠ¡å®ä¾‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„APIå¯†é’¥
            deepseek_key = os.getenv('DEEPSEEK_API_KEY')
            minimax_key = os.getenv('MINIMAX_API_KEY')
            minimax_group_id = os.getenv('MINIMAX_GROUP_ID')
            stepchat_key = os.getenv('STEPCHAT_API_KEY')
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•å¯†é’¥æˆ–ç©ºå€¼
            test_keys = ['sk-1234567890abcdef', 'test_key', '', None]
            
            # åˆå§‹åŒ–DeepSeek
            if deepseek_key and deepseek_key not in test_keys:
                try:
                    self.ai_services['deepseek'] = DeepSeekAI(deepseek_key)
                    logger.info("DeepSeek AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    logger.error(f"DeepSeekåˆå§‹åŒ–å¤±è´¥: {e}")
            
            # åˆå§‹åŒ–MiniMax
            if minimax_key and minimax_group_id and minimax_key not in test_keys:
                try:
                    self.ai_services['minimax'] = MinimaxAI(minimax_key, minimax_group_id)
                    logger.info("MiniMax AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    logger.error(f"MiniMaxåˆå§‹åŒ–å¤±è´¥: {e}")
            
            # åˆå§‹åŒ–StepChat
            if stepchat_key and stepchat_key not in test_keys:
                try:
                    self.ai_services['stepchat'] = StepChatAI(stepchat_key)
                    logger.info("StepChat AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    logger.error(f"StepChatåˆå§‹åŒ–å¤±è´¥: {e}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„AIæœåŠ¡
            if not self.ai_services:
                logger.warning("æ²¡æœ‰å¯ç”¨çš„AIæœåŠ¡ï¼Œå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self.simulation_mode = True
            else:
                logger.info(f"æˆåŠŸåˆå§‹åŒ– {len(self.ai_services)} ä¸ªAIæœåŠ¡")
                self.simulation_mode = False  # æœ‰çœŸå®æœåŠ¡æ—¶ç¦ç”¨æ¨¡æ‹Ÿæ¨¡å¼
                
        except Exception as e:
            logger.error(f"AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.simulation_mode = True
        
    def get_ai_response(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–AIå›å¤ - æ•´åˆå¤šä¸ªAIæ¨¡å‹"""
        try:
            message = data.get('message', '')
            session_id = data.get('session_id', 'default')
            user_id = data.get('user_id', 'user')
            
            # åˆ†ææ¶ˆæ¯å†…å®¹å’Œä¸Šä¸‹æ–‡
            context = self._analyze_context(message, session_id)
            
            # é€‰æ‹©åˆé€‚çš„AIæ¨¡å‹ç»„åˆ
            selected_models = self._select_ai_models(context, user_id)
            
            # ç”Ÿæˆå¤šæ ·æ€§å›å¤
            responses = self._generate_diverse_responses(message, selected_models, context)
            
            # æ•´åˆå›å¤
            final_response = self._integrate_responses(responses, context)
            
            # æ›´æ–°å¯¹è¯å†å²
            self._update_conversation_history(session_id, message, final_response, context)
            
            return {
                'response': final_response,
                'ai_models_used': selected_models,
                'context': context,
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Unified AI service error: {str(e)}")
            return {
                'response': f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è®©æˆ‘é‡æ–°æ€è€ƒä¸€ä¸‹ï¼š{data.get('message', '')}",
                'ai_models_used': ['fallback'],
                'context': {'error': str(e)},
                'timestamp': datetime.utcnow().isoformat()
            }
    
    def _analyze_context(self, message: str, session_id: str) -> Dict[str, Any]:
        """åˆ†ææ¶ˆæ¯ä¸Šä¸‹æ–‡"""
        context = {
            'message_length': len(message),
            'sentiment': self._analyze_sentiment(message),
            'topic': self._detect_topic(message),
            'complexity': self._assess_complexity(message),
            'conversation_history': self.conversation_history.get(session_id, []),
            'time_of_day': datetime.now().hour
        }
        
        # åˆ†æç”¨æˆ·åå¥½
        if session_id in self.user_preferences:
            context['user_preferences'] = self.user_preferences[session_id]
        
        return context
    
    def _analyze_sentiment(self, message: str) -> str:
        """åˆ†ææ¶ˆæ¯æƒ…æ„Ÿ"""
        positive_words = ['å¥½', 'æ£’', 'å–œæ¬¢', 'çˆ±', 'å¼€å¿ƒ', 'é«˜å…´', 'æ»¡æ„', 'ä¼˜ç§€', 'ç²¾å½©', 'è°¢è°¢', 'æ„Ÿè°¢']
        negative_words = ['ä¸å¥½', 'è®¨åŒ', 'éš¾è¿‡', 'å¤±æœ›', 'ç³Ÿç³•', 'é—®é¢˜', 'å›°éš¾', 'ç—›è‹¦', 'çƒ¦', 'ç´¯']
        
        positive_count = sum(1 for word in positive_words if word in message)
        negative_count = sum(1 for word in negative_words if word in message)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    def _detect_topic(self, message: str) -> str:
        """æ£€æµ‹æ¶ˆæ¯ä¸»é¢˜"""
        topics = {
            'technology': ['æŠ€æœ¯', 'ç¼–ç¨‹', 'ä»£ç ', 'è½¯ä»¶', 'ç¡¬ä»¶', 'ç”µè„‘', 'æ‰‹æœº', 'äº’è”ç½‘', 'AI', 'äººå·¥æ™ºèƒ½'],
            'business': ['å•†ä¸š', 'å·¥ä½œ', 'å…¬å¸', 'é¡¹ç›®', 'ç®¡ç†', 'å¸‚åœº', 'é”€å”®', 'æŠ•èµ„', 'åˆ›ä¸š'],
            'education': ['å­¦ä¹ ', 'æ•™è‚²', 'å­¦æ ¡', 'è¯¾ç¨‹', 'çŸ¥è¯†', 'è€ƒè¯•', 'è€å¸ˆ', 'å­¦ç”Ÿ', 'åŸ¹è®­'],
            'entertainment': ['å¨±ä¹', 'æ¸¸æˆ', 'ç”µå½±', 'éŸ³ä¹', 'è‰ºæœ¯', 'æ—…æ¸¸', 'ç¾é£Ÿ', 'è¿åŠ¨', 'ç¬‘è¯'],
            'personal': ['ä¸ªäºº', 'ç”Ÿæ´»', 'å®¶åº­', 'æœ‹å‹', 'æƒ…æ„Ÿ', 'å¥åº·', 'å¿ƒæƒ…', 'æ¢¦æƒ³', 'æœªæ¥']
        }
        
        for topic, keywords in topics.items():
            if any(keyword in message for keyword in keywords):
                return topic
        
        return 'general'
    
    def _assess_complexity(self, message: str) -> str:
        """è¯„ä¼°æ¶ˆæ¯å¤æ‚åº¦"""
        if len(message) > 100 or any(char in message for char in ['ï¼Ÿ', '!', 'ã€‚', 'ï¼Œ']):
            return 'complex'
        elif len(message) > 50:
            return 'medium'
        else:
            return 'simple'
    
    def _select_ai_models(self, context: Dict[str, Any], user_id: str) -> List[str]:
        """é€‰æ‹©åˆé€‚çš„AIæ¨¡å‹ç»„åˆ"""
        selected_models = []
        
        # åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹ï¼Œä»æ‰€æœ‰å¯ç”¨æ¨¡å‹ä¸­é€‰æ‹©
        available_models = list(self.ai_models.keys()) if self.simulation_mode else list(self.ai_services.keys())
        
        # åŸºäºæ¶ˆæ¯å¤æ‚åº¦é€‰æ‹©
        if context['complexity'] == 'complex':
            if 'deepseek' in available_models:
                selected_models.append('deepseek')  # å¤æ‚é—®é¢˜ç”¨DeepSeek
        
        # åŸºäºæƒ…æ„Ÿé€‰æ‹©
        if context['sentiment'] == 'positive':
            if 'minimax' in available_models:
                selected_models.append('minimax')  # ç§¯ææƒ…æ„Ÿç”¨MiniMax
        elif context['sentiment'] == 'negative':
            if 'stepchat' in available_models:
                selected_models.append('stepchat')  # æ¶ˆææƒ…æ„Ÿç”¨StepChatæä¾›åˆ›æ„è§£å†³æ–¹æ¡ˆ
        
        # åŸºäºä¸»é¢˜é€‰æ‹©
        if context['topic'] == 'technology':
            if 'deepseek' in available_models:
                selected_models.append('deepseek')
        elif context['topic'] == 'entertainment':
            if 'stepchat' in available_models:
                selected_models.append('stepchat')
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹
        if not selected_models:
            # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©
            if 'minimax' in available_models:
                selected_models.append('minimax')
            elif 'deepseek' in available_models:
                selected_models.append('deepseek')
            elif 'stepchat' in available_models:
                selected_models.append('stepchat')
        
        # éšæœºæ·»åŠ ç¬¬äºŒä¸ªæ¨¡å‹ä»¥å¢åŠ å¤šæ ·æ€§
        if len(selected_models) == 1 and random.random() < 0.3:
            remaining_models = [m for m in available_models if m not in selected_models]
            if remaining_models:
                selected_models.append(random.choice(remaining_models))
        
        return selected_models
    
    def _generate_diverse_responses(self, message: str, selected_models: List[str], context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå¤šæ ·æ€§å›å¤"""
        responses = []
        
        for model_name in selected_models:
            try:
                model_info = self.ai_models[model_name]
                
                # æ ¹æ®æ¨¡å‹ç‰¹æ€§è°ƒæ•´æ¶ˆæ¯
                adjusted_message = self._adjust_message_for_model(message, model_info, context)
                
                # ç”Ÿæˆå›å¤
                response = self._generate_single_response(adjusted_message, model_name, context)
                
                responses.append({
                    'model': model_name,
                    'response': response,
                    'personality': model_info['personality'],
                    'style': model_info['style']
                })
                
            except Exception as e:
                logger.error(f"Error generating response for {model_name}: {str(e)}")
                # ç”Ÿæˆå¤‡ç”¨å›å¤
                responses.append({
                    'model': model_name,
                    'response': f"[{model_info['name']}] æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ï¼š{message}",
                    'personality': model_info['personality'],
                    'style': model_info['style']
                })
        
        return responses
    
    def _adjust_message_for_model(self, message: str, model_info: Dict[str, Any], context: Dict[str, Any]) -> str:
        """æ ¹æ®æ¨¡å‹ç‰¹æ€§è°ƒæ•´æ¶ˆæ¯"""
        if model_info['style'] == 'formal':
            # ä¸ºæ­£å¼é£æ ¼æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
            return f"è¯·ä»¥ä¸“ä¸šã€ä¸¥è°¨çš„æ–¹å¼å›ç­”ï¼š{message}"
        elif model_info['style'] == 'casual':
            # ä¸ºå‹å¥½é£æ ¼æ·»åŠ æƒ…æ„Ÿå…ƒç´ 
            return f"è¯·ä»¥å‹å¥½ã€è½»æ¾çš„æ–¹å¼å›ç­”ï¼š{message}"
        elif model_info['style'] == 'creative':
            # ä¸ºåˆ›æ„é£æ ¼æ·»åŠ åˆ›æ–°å…ƒç´ 
            return f"è¯·ä»¥åˆ›æ–°ã€å¯Œæœ‰æƒ³è±¡åŠ›çš„æ–¹å¼å›ç­”ï¼š{message}"
        
        return message
    
    def _generate_single_response(self, message: str, model_name: str, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆå•ä¸ªAIæ¨¡å‹çš„å›å¤"""
        try:
            if self.simulation_mode:
                # æ¨¡æ‹Ÿæ¨¡å¼
                return self._generate_simulated_response(message, model_name)
            
            # çœŸå®APIè°ƒç”¨
            if model_name in self.ai_services:
                service = self.ai_services[model_name]
                # ä¼ é€’ç”¨æˆ·IDå’Œæ¶ˆæ¯
                response = service.generate_response(
                    prompt=message,
                    user_id=context.get('user_id', 'user1')
                )
                return response
            else:
                return self._generate_simulated_response(message, model_name)
                
        except Exception as e:
            logger.error(f"Error in {model_name} response generation: {str(e)}")
            return self._generate_simulated_response(message, model_name)
    
    def _generate_simulated_response(self, message: str, model_name: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå›å¤"""
        if model_name == 'deepseek':
            responses = [
                f"ä»æŠ€æœ¯è§’åº¦æ¥çœ‹ï¼Œ{message} è¿™ä¸ªé—®é¢˜éœ€è¦æ·±å…¥åˆ†æã€‚",
                f"åŸºäºæˆ‘çš„ç†è§£ï¼Œ{message} æ¶‰åŠå¤šä¸ªå±‚é¢çš„è€ƒè™‘ã€‚",
                f"è®©æˆ‘ä»é€»è¾‘è§’åº¦åˆ†æä¸€ä¸‹ï¼š{message}",
                f"è¿™ä¸ªé—®é¢˜å¾ˆæœ‰è¶£ï¼Œ{message} è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†è§£é‡Šã€‚",
                f"ä»ä¸“ä¸šè§’åº¦æ¥è¯´ï¼Œ{message} éœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ ã€‚",
                f"æ ¹æ®æˆ‘çš„åˆ†æï¼Œ{message} å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦æ¥ç†è§£ã€‚",
                f"ä»æŠ€æœ¯å±‚é¢çœ‹ï¼Œ{message} æ˜¯ä¸€ä¸ªå€¼å¾—æ·±å…¥ç ”ç©¶çš„è¯é¢˜ã€‚"
            ]
        elif model_name == 'minimax':
            responses = [
                f"å“ˆå“ˆï¼Œ{message} è¿™ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€å‘¢ï¼",
                f"æˆ‘ç†è§£æ‚¨çš„æƒ³æ³•ï¼Œ{message} ç¡®å®å€¼å¾—è®¨è®ºã€‚",
                f"è°¢è°¢æ‚¨åˆ†äº«è¿™ä¸ªæƒ³æ³•ï¼Œ{message} è®©æˆ‘æƒ³æƒ³...",
                f"å“‡ï¼Œ{message} è¿™ä¸ªæƒ³æ³•å¾ˆæ£’ï¼",
                f"æˆ‘å®Œå…¨ç†è§£æ‚¨çš„æ„Ÿå—ï¼Œ{message} æˆ‘ä»¬ä¸€èµ·æ¢è®¨ä¸€ä¸‹å§ï¼",
                f"è¿™çœŸæ˜¯ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼Œ{message} è®©æˆ‘æ¥å¸®æ‚¨åˆ†æä¸€ä¸‹ã€‚",
                f"æˆ‘å¾ˆé«˜å…´æ‚¨é—®è¿™ä¸ªé—®é¢˜ï¼Œ{message} è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚"
            ]
        elif model_name == 'stepchat':
            responses = [
                f"âœ¨ å…³äº {message}ï¼Œæˆ‘æœ‰ä¸€ä¸ªåˆ›æ„æƒ³æ³•ï¼",
                f"ğŸŒŸ è®©æˆ‘ä»¬ç”¨å…¨æ–°çš„è§†è§’æ¥çœ‹å¾… {message}",
                f"ğŸ’¡ è¿™è®©æˆ‘æƒ³åˆ°äº†ä¸€ä¸ªæœ‰è¶£çš„è§£å†³æ–¹æ¡ˆï¼š{message}",
                f"ğŸ¨ ä»è‰ºæœ¯çš„è§’åº¦ï¼Œ{message} å¯ä»¥è¿™æ ·ç†è§£...",
                f"ğŸš€ è®©æˆ‘ä»¬è·³å‡ºå¸¸è§„æ€ç»´ï¼Œ{message} å…¶å®å¯ä»¥è¿™æ ·æ€è€ƒ...",
                f"ğŸŒˆ è¿™æ˜¯ä¸€ä¸ªå……æ»¡å¯èƒ½æ€§çš„é—®é¢˜ï¼Œ{message} è®©æˆ‘ä¸ºæ‚¨å±•å¼€æƒ³è±¡ï¼",
                f"ğŸ­ ä»åˆ›æ„çš„è§’åº¦çœ‹ï¼Œ{message} æœ‰å¾ˆå¤šæœ‰è¶£çš„å¯èƒ½æ€§ã€‚"
            ]
        else:
            responses = [f"AIå›å¤ï¼š{message}"]
        
        return random.choice(responses)
    
    def _integrate_responses(self, responses: List[Dict[str, Any]], context: Dict[str, Any]) -> str:
        """æ•´åˆå¤šä¸ªAIçš„å›å¤"""
        if len(responses) == 1:
            return responses[0]['response']
        
        # æ•´åˆå¤šä¸ªå›å¤
        integrated_parts = []
        
        for i, response in enumerate(responses):
            model_name = response['model']
            model_info = self.ai_models[model_name]
            
            # æ·»åŠ æ¨¡å‹æ ‡è¯†
            if len(responses) > 1:
                integrated_parts.append(f"[{model_info['name']}] {response['response']}")
            else:
                integrated_parts.append(response['response'])
        
        # æ ¹æ®å›å¤æ•°é‡é€‰æ‹©æ•´åˆæ–¹å¼
        if len(responses) == 2:
            # ä¸¤ä¸ªå›å¤ï¼šå¯¹è¯å¼æ•´åˆ
            return f"{integrated_parts[0]}\n\n{integrated_parts[1]}"
        else:
            # å¤šä¸ªå›å¤ï¼šåˆ—è¡¨å¼æ•´åˆ
            return "\n\n".join(integrated_parts)
    
    def _update_conversation_history(self, session_id: str, user_message: str, ai_response: str, context: Dict[str, Any]):
        """æ›´æ–°å¯¹è¯å†å²"""
        if session_id not in self.conversation_history:
            self.conversation_history[session_id] = []
        
        self.conversation_history[session_id].append({
            'user_message': user_message,
            'ai_response': ai_response,
            'context': context,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.conversation_history[session_id]) > 50:
            self.conversation_history[session_id] = self.conversation_history[session_id][-25:]
    
    def get_ai_models_info(self) -> Dict[str, Any]:
        """è·å–AIæ¨¡å‹ä¿¡æ¯"""
        return {
            'models': self.ai_models,
            'total_models': len(self.ai_models),
            'description': 'ç»Ÿä¸€AIæœåŠ¡æ•´åˆäº†å¤šä¸ªAIæ¨¡å‹ï¼Œæä¾›å¤šæ ·åŒ–çš„èŠå¤©ä½“éªŒ',
            'simulation_mode': self.simulation_mode,
            'available_services': list(self.ai_services.keys())
        }

# å…¨å±€å®ä¾‹
unified_ai_service = UnifiedAIService()

def get_unified_ai_response(data: Dict[str, Any]) -> str:
    """è·å–ç»Ÿä¸€AIå›å¤"""
    result = unified_ai_service.get_ai_response(data)
    return result['response'] 